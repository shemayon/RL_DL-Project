{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0464ed9-a467-4549-9391-97b4ab149524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 157s 100ms/step\n",
      "313/313 [==============================] - 26s 84ms/step\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 7s 11ms/step - loss: 0.3279 - accuracy: 0.1438 - val_loss: 0.3148 - val_accuracy: 0.1922\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.3069 - accuracy: 0.2308 - val_loss: 0.3003 - val_accuracy: 0.2583\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.2967 - accuracy: 0.2640 - val_loss: 0.2925 - val_accuracy: 0.2901\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.2908 - accuracy: 0.2857 - val_loss: 0.2882 - val_accuracy: 0.2995\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.2865 - accuracy: 0.3005 - val_loss: 0.2845 - val_accuracy: 0.3078\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2833 - accuracy: 0.3101 - val_loss: 0.2828 - val_accuracy: 0.3087\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2803 - accuracy: 0.3183 - val_loss: 0.2787 - val_accuracy: 0.3232\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2783 - accuracy: 0.3268 - val_loss: 0.2774 - val_accuracy: 0.3301\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2764 - accuracy: 0.3339 - val_loss: 0.2759 - val_accuracy: 0.3321\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2748 - accuracy: 0.3400 - val_loss: 0.2740 - val_accuracy: 0.3359\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2733 - accuracy: 0.3418 - val_loss: 0.2728 - val_accuracy: 0.3443\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2719 - accuracy: 0.3461 - val_loss: 0.2719 - val_accuracy: 0.3453\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2711 - accuracy: 0.3486 - val_loss: 0.2701 - val_accuracy: 0.3561\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2700 - accuracy: 0.3532 - val_loss: 0.2705 - val_accuracy: 0.3542\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2687 - accuracy: 0.3610 - val_loss: 0.2689 - val_accuracy: 0.3547\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2679 - accuracy: 0.3637 - val_loss: 0.2686 - val_accuracy: 0.3527\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2669 - accuracy: 0.3656 - val_loss: 0.2674 - val_accuracy: 0.3635\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2663 - accuracy: 0.3676 - val_loss: 0.2665 - val_accuracy: 0.3660\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2656 - accuracy: 0.3674 - val_loss: 0.2659 - val_accuracy: 0.3656\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2647 - accuracy: 0.3710 - val_loss: 0.2647 - val_accuracy: 0.3705\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2640 - accuracy: 0.3731 - val_loss: 0.2643 - val_accuracy: 0.3719\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2637 - accuracy: 0.3771 - val_loss: 0.2638 - val_accuracy: 0.3735\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2627 - accuracy: 0.3779 - val_loss: 0.2654 - val_accuracy: 0.3674\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2624 - accuracy: 0.3773 - val_loss: 0.2628 - val_accuracy: 0.3779\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2615 - accuracy: 0.3822 - val_loss: 0.2631 - val_accuracy: 0.3750\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2612 - accuracy: 0.3813 - val_loss: 0.2633 - val_accuracy: 0.3783\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2607 - accuracy: 0.3854 - val_loss: 0.2619 - val_accuracy: 0.3762\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2603 - accuracy: 0.3866 - val_loss: 0.2632 - val_accuracy: 0.3763\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2597 - accuracy: 0.3871 - val_loss: 0.2609 - val_accuracy: 0.3819\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2594 - accuracy: 0.3885 - val_loss: 0.2588 - val_accuracy: 0.3925\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2585 - accuracy: 0.3917 - val_loss: 0.2598 - val_accuracy: 0.3877\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2584 - accuracy: 0.3897 - val_loss: 0.2596 - val_accuracy: 0.3891\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2580 - accuracy: 0.3919 - val_loss: 0.2598 - val_accuracy: 0.3895\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2573 - accuracy: 0.3960 - val_loss: 0.2592 - val_accuracy: 0.3850\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2571 - accuracy: 0.3939 - val_loss: 0.2577 - val_accuracy: 0.3963\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2568 - accuracy: 0.3963 - val_loss: 0.2585 - val_accuracy: 0.3900\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2567 - accuracy: 0.3990 - val_loss: 0.2610 - val_accuracy: 0.3796\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2559 - accuracy: 0.3994 - val_loss: 0.2591 - val_accuracy: 0.3815\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2560 - accuracy: 0.3990 - val_loss: 0.2575 - val_accuracy: 0.3903\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2556 - accuracy: 0.3999 - val_loss: 0.2589 - val_accuracy: 0.3908\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2551 - accuracy: 0.3996 - val_loss: 0.2552 - val_accuracy: 0.3995\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2547 - accuracy: 0.4033 - val_loss: 0.2555 - val_accuracy: 0.3973\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2543 - accuracy: 0.4032 - val_loss: 0.2552 - val_accuracy: 0.4010\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2538 - accuracy: 0.4063 - val_loss: 0.2561 - val_accuracy: 0.4022\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2538 - accuracy: 0.4061 - val_loss: 0.2556 - val_accuracy: 0.4025\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2538 - accuracy: 0.4065 - val_loss: 0.2532 - val_accuracy: 0.4088\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2532 - accuracy: 0.4093 - val_loss: 0.2552 - val_accuracy: 0.4098\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2525 - accuracy: 0.4104 - val_loss: 0.2563 - val_accuracy: 0.4014\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2524 - accuracy: 0.4100 - val_loss: 0.2542 - val_accuracy: 0.4068\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2524 - accuracy: 0.4095 - val_loss: 0.2535 - val_accuracy: 0.4053\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2521 - accuracy: 0.4106 - val_loss: 0.2541 - val_accuracy: 0.4052\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2520 - accuracy: 0.4116 - val_loss: 0.2553 - val_accuracy: 0.3985\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2519 - accuracy: 0.4106 - val_loss: 0.2526 - val_accuracy: 0.4092\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2516 - accuracy: 0.4131 - val_loss: 0.2532 - val_accuracy: 0.4109\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2513 - accuracy: 0.4110 - val_loss: 0.2530 - val_accuracy: 0.4113\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2506 - accuracy: 0.4159 - val_loss: 0.2544 - val_accuracy: 0.4058\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2504 - accuracy: 0.4154 - val_loss: 0.2519 - val_accuracy: 0.4157\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2502 - accuracy: 0.4153 - val_loss: 0.2529 - val_accuracy: 0.4064\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2502 - accuracy: 0.4172 - val_loss: 0.2511 - val_accuracy: 0.4181\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2500 - accuracy: 0.4179 - val_loss: 0.2534 - val_accuracy: 0.4069\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2499 - accuracy: 0.4175 - val_loss: 0.2531 - val_accuracy: 0.4055\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2492 - accuracy: 0.4211 - val_loss: 0.2517 - val_accuracy: 0.4097\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2493 - accuracy: 0.4193 - val_loss: 0.2510 - val_accuracy: 0.4126\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2493 - accuracy: 0.4221 - val_loss: 0.2513 - val_accuracy: 0.4172\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2489 - accuracy: 0.4223 - val_loss: 0.2508 - val_accuracy: 0.4168\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2486 - accuracy: 0.4213 - val_loss: 0.2502 - val_accuracy: 0.4194\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2484 - accuracy: 0.4247 - val_loss: 0.2489 - val_accuracy: 0.4236\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2484 - accuracy: 0.4244 - val_loss: 0.2499 - val_accuracy: 0.4191\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2480 - accuracy: 0.4243 - val_loss: 0.2496 - val_accuracy: 0.4188\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2478 - accuracy: 0.4269 - val_loss: 0.2518 - val_accuracy: 0.4116\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2482 - accuracy: 0.4234 - val_loss: 0.2504 - val_accuracy: 0.4139\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2478 - accuracy: 0.4256 - val_loss: 0.2530 - val_accuracy: 0.4070\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2475 - accuracy: 0.4260 - val_loss: 0.2509 - val_accuracy: 0.4149\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2471 - accuracy: 0.4263 - val_loss: 0.2499 - val_accuracy: 0.4195\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2471 - accuracy: 0.4263 - val_loss: 0.2488 - val_accuracy: 0.4235\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2469 - accuracy: 0.4284 - val_loss: 0.2489 - val_accuracy: 0.4221\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2468 - accuracy: 0.4261 - val_loss: 0.2483 - val_accuracy: 0.4263\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2467 - accuracy: 0.4265 - val_loss: 0.2473 - val_accuracy: 0.4211\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2465 - accuracy: 0.4294 - val_loss: 0.2489 - val_accuracy: 0.4225\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2463 - accuracy: 0.4304 - val_loss: 0.2470 - val_accuracy: 0.4279\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2462 - accuracy: 0.4305 - val_loss: 0.2489 - val_accuracy: 0.4190\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2457 - accuracy: 0.4332 - val_loss: 0.2517 - val_accuracy: 0.4151\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2457 - accuracy: 0.4331 - val_loss: 0.2502 - val_accuracy: 0.4165\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2453 - accuracy: 0.4333 - val_loss: 0.2482 - val_accuracy: 0.4261\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2458 - accuracy: 0.4316 - val_loss: 0.2477 - val_accuracy: 0.4267\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.2452 - accuracy: 0.4343 - val_loss: 0.2499 - val_accuracy: 0.4146\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2450 - accuracy: 0.4321 - val_loss: 0.2493 - val_accuracy: 0.4215\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2449 - accuracy: 0.4341 - val_loss: 0.2477 - val_accuracy: 0.4233\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2453 - accuracy: 0.4312 - val_loss: 0.2478 - val_accuracy: 0.4260\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2449 - accuracy: 0.4322 - val_loss: 0.2471 - val_accuracy: 0.4314\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2444 - accuracy: 0.4363 - val_loss: 0.2472 - val_accuracy: 0.4296\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2442 - accuracy: 0.4363 - val_loss: 0.2476 - val_accuracy: 0.4255\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2443 - accuracy: 0.4357 - val_loss: 0.2453 - val_accuracy: 0.4329\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2442 - accuracy: 0.4384 - val_loss: 0.2475 - val_accuracy: 0.4221\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2441 - accuracy: 0.4386 - val_loss: 0.2463 - val_accuracy: 0.4325\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2441 - accuracy: 0.4380 - val_loss: 0.2444 - val_accuracy: 0.4337\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2439 - accuracy: 0.4360 - val_loss: 0.2473 - val_accuracy: 0.4280\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2436 - accuracy: 0.4372 - val_loss: 0.2498 - val_accuracy: 0.4233\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2436 - accuracy: 0.4396 - val_loss: 0.2459 - val_accuracy: 0.4281\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.2437 - accuracy: 0.4382 - val_loss: 0.2477 - val_accuracy: 0.4296\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2477 - accuracy: 0.4296\n",
      "Accuracy: 42.96%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Reshape\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "num_classes = 10\n",
    "\n",
    "# Normalize input images and convert labels to binary class matrices\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Load pre-trained ResNet-50 without top (classification) layer\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze the layers in the ResNet-50 model\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Extract features from the images using ResNet-50\n",
    "x_train_features = preprocess_input(x_train)\n",
    "x_test_features = preprocess_input(x_test)\n",
    "\n",
    "# Reshape the features for LSTM input\n",
    "x_train_features = Reshape((1, 1, 2048))(resnet.predict(x_train_features))\n",
    "x_test_features = Reshape((1, 1, 2048))(resnet.predict(x_test_features))\n",
    "\n",
    "# Define RNN model architecture\n",
    "input_shape = (1, 1, 2048)\n",
    "rnn_input = Input(shape=input_shape)\n",
    "rnn_layer = Reshape((1, 2048))(rnn_input)\n",
    "rnn_layer = LSTM(64)(rnn_layer)\n",
    "output_layer = Dense(num_classes, activation='sigmoid')(rnn_layer)\n",
    "model = Model(inputs=rnn_input, outputs=output_layer)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train_features, y_train, batch_size=128, epochs=100, validation_data=(x_test_features, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(x_test_features, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f5b09-3bde-40c8-893d-75e888215c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
